# 评估器网络（Scorer Network）设计方案

## 一、任务定义

### 1.1 任务描述

训练一个**评估器网络**，用于评估在给定姿态和刀具参数下，加工该模型的质量分数。

### 1.2 输入输出

**输入**:
1. **模型点云**: 通过 Octree 表示的3D几何信息
2. **旋转矩阵（姿态）**: 从338个预定义旋转矩阵中选择一个 (3, 3)
3. **刀具参数**: 4维向量 [param1, param2, param3, param4]

**输出**:
- **评分**: 单个浮点数，表示该姿态下的加工质量（越小越好）

**Ground Truth**:
- `labels`: [338] 维向量，每个元素对应一个预定义姿态的真实分数
- index i 的分数对应 rotation_matrices[i]

---

## 二、网络架构设计

### 2.1 整体架构

```
┌─────────────────────────────────────────────────────────┐
│                    输入层                                │
├─────────────────────────────────────────────────────────┤
│  1. Octree (点云)     [N_nodes, 4]                      │
│  2. Rotation Matrix   [3, 3]                            │
│  3. Tool Params       [4]                               │
└─────────────────────────────────────────────────────────┘
                        ↓
┌─────────────────────────────────────────────────────────┐
│                 特征提取分支                             │
├─────────────────────────────────────────────────────────┤
│  ┌─────────────────┐  ┌──────────────┐  ┌────────────┐ │
│  │  Octree Encoder │  │ Rotation MLP │  │  Tool MLP  │ │
│  │   (UNet/SegNet) │  │   (Flatten)  │  │   (FC)     │ │
│  │       ↓         │  │      ↓       │  │     ↓      │ │
│  │   [B, C_geo]    │  │  [B, C_rot]  │  │ [B, C_tool]│ │
│  └─────────────────┘  └──────────────┘  └────────────┘ │
└─────────────────────────────────────────────────────────┘
                        ↓
┌─────────────────────────────────────────────────────────┐
│                   特征融合                               │
├─────────────────────────────────────────────────────────┤
│         Concat: [B, C_geo + C_rot + C_tool]             │
│                        ↓                                 │
│              Fusion MLP (多层感知机)                     │
└─────────────────────────────────────────────────────────┘
                        ↓
┌─────────────────────────────────────────────────────────┐
│                   输出层                                 │
├─────────────────────────────────────────────────────────┤
│               Score Head: [B] → 单个分数                │
└─────────────────────────────────────────────────────────┘
```

---

## 三、详细实现

### 3.1 新建评估器模型文件

**文件**: `projects/ocnn/models/scorer_net.py`

```python
import torch
import torch.nn as nn
from typing import Optional
import ocnn
from ocnn.octree import Octree


class ScorerNet(nn.Module):
    """
    评估器网络：给定点云、姿态、刀具参数，预测加工质量分数
    
    输入:
        - data: [N_nodes, C_in] 八叉树节点特征
        - octree: Octree对象
        - depth: int
        - query_pts: [N_pts, 4] 查询点
        - rotation_matrix: [B, 3, 3] 旋转矩阵（姿态）
        - tool_params: [B, 4] 刀具参数
    
    输出:
        - score: [B] 评分（越小越好）
    """
    
    def __init__(
        self,
        in_channels: int = 4,
        geo_channels: int = 256,      # 几何特征维度
        rot_channels: int = 128,      # 旋转特征维度
        tool_channels: int = 64,      # 刀具特征维度
        interp: str = 'linear',
        nempty: bool = False,
        use_decoder: bool = False,    # 是否使用解码器
        **kwargs
    ):
        super().__init__()
        self.in_channels = in_channels
        self.geo_channels = geo_channels
        self.rot_channels = rot_channels
        self.tool_channels = tool_channels
        self.nempty = nempty
        self.use_decoder = use_decoder
        
        # ============ 1. 几何特征提取（使用现有的编码器）============
        self._config_geometry_encoder()
        
        # 编码器
        self.conv1 = ocnn.modules.OctreeConvBnRelu(
            in_channels, self.encoder_channel[0], nempty=nempty
        )
        self.downsample = nn.ModuleList([
            ocnn.modules.OctreeConvBnRelu(
                self.encoder_channel[i], self.encoder_channel[i + 1],
                kernel_size=[2], stride=2, nempty=nempty
            ) for i in range(self.encoder_stages)
        ])
        self.encoder = nn.ModuleList([
            ocnn.modules.OctreeResBlocks(
                self.encoder_channel[i + 1], self.encoder_channel[i + 1],
                self.encoder_blocks[i], self.bottleneck, nempty, self.resblk
            ) for i in range(self.encoder_stages)
        ])
        
        self.octree_interp = ocnn.nn.OctreeInterp(interp, nempty)
        
        # 几何特征投影
        self.geo_proj = nn.Sequential(
            nn.Linear(self.encoder_channel[-1], 512),
            nn.ReLU(inplace=True),
            nn.BatchNorm1d(512),
            nn.Dropout(0.3),
            nn.Linear(512, geo_channels),
            nn.ReLU(inplace=True),
        )
        
        # ============ 2. 旋转矩阵特征提取 ============
        self.rotation_encoder = nn.Sequential(
            nn.Flatten(),  # [B, 3, 3] -> [B, 9]
            nn.Linear(9, 64),
            nn.ReLU(inplace=True),
            nn.BatchNorm1d(64),
            nn.Dropout(0.2),
            nn.Linear(64, rot_channels),
            nn.ReLU(inplace=True),
        )
        
        # ============ 3. 刀具参数特征提取 ============
        self.tool_encoder = nn.Sequential(
            nn.Linear(4, 32),
            nn.ReLU(inplace=True),
            nn.BatchNorm1d(32),
            nn.Dropout(0.2),
            nn.Linear(32, tool_channels),
            nn.ReLU(inplace=True),
        )
        
        # ============ 4. 特征融合 ============
        fusion_dim = geo_channels + rot_channels + tool_channels
        self.fusion_mlp = nn.Sequential(
            nn.Linear(fusion_dim, 512),
            nn.ReLU(inplace=True),
            nn.BatchNorm1d(512),
            nn.Dropout(0.3),
            nn.Linear(512, 256),
            nn.ReLU(inplace=True),
            nn.BatchNorm1d(256),
            nn.Dropout(0.3),
            nn.Linear(256, 128),
            nn.ReLU(inplace=True),
        )
        
        # ============ 5. 评分头 ============
        self.score_head = nn.Sequential(
            nn.Linear(128, 64),
            nn.ReLU(inplace=True),
            nn.Linear(64, 1),
            # 注意：不使用激活函数，允许输出任意实数
        )
    
    def _config_geometry_encoder(self):
        """配置几何编码器（参考UNet）"""
        self.encoder_blocks = [2, 3, 4, 6, 3]
        self.encoder_channel = [32, 64, 128, 256, 512]
        self.encoder_stages = len(self.encoder_blocks)
        self.bottleneck = 1
        self.resblk = ocnn.modules.OctreeResBlock2
    
    def encode_geometry(self, data, octree, depth, query_pts):
        """提取几何特征"""
        # 编码器前向
        convd = dict()
        convd[depth] = self.conv1(data, octree, depth)
        for i in range(self.encoder_stages):
            d = depth - i
            conv = self.downsample[i](convd[d], octree, d)
            convd[d - 1] = self.encoder[i](conv, octree, d - 1)
        
        # 获取最深层特征
        deepest_depth = depth - self.encoder_stages
        deepest_feat = convd[deepest_depth]  # [N_nodes_deep, C]
        
        # 插值到点云
        point_feat = self.octree_interp(
            deepest_feat, octree, deepest_depth, query_pts
        )  # [N_pts, C]
        
        # 全局平均池化
        batch_id = query_pts[:, 3].long()
        B = batch_id.max().item() + 1
        
        geo_feat = self._batch_mean_pool(point_feat, batch_id, B)  # [B, C]
        
        # 投影到目标维度
        geo_feat = self.geo_proj(geo_feat)  # [B, geo_channels]
        
        return geo_feat
    
    @staticmethod
    def _batch_mean_pool(point_feat, batch_id, B):
        """批量平均池化"""
        C = point_feat.size(1)
        sum_feat = torch.zeros(B, C, device=point_feat.device, dtype=point_feat.dtype)
        sum_feat.index_add_(0, batch_id, point_feat)
        cnt = torch.bincount(batch_id, minlength=B).clamp_min(1).float()
        return sum_feat / cnt.unsqueeze(1).to(point_feat.device)
    
    def forward(
        self,
        data: torch.Tensor,          # [N_nodes, C_in]
        octree: Octree,
        depth: int,
        query_pts: torch.Tensor,     # [N_pts, 4]
        rotation_matrix: torch.Tensor,  # [B, 3, 3]
        tool_params: torch.Tensor    # [B, 4]
    ):
        """
        前向传播
        
        Returns:
            score: [B] 评分
        """
        B = rotation_matrix.size(0)
        
        # 1. 提取几何特征
        geo_feat = self.encode_geometry(data, octree, depth, query_pts)  # [B, geo_channels]
        
        # 2. 提取旋转特征
        rot_feat = self.rotation_encoder(rotation_matrix)  # [B, rot_channels]
        
        # 3. 提取刀具特征
        tool_feat = self.tool_encoder(tool_params)  # [B, tool_channels]
        
        # 4. 特征融合
        fused_feat = torch.cat([geo_feat, rot_feat, tool_feat], dim=1)  # [B, fusion_dim]
        fused_feat = self.fusion_mlp(fused_feat)  # [B, 128]
        
        # 5. 预测分数
        score = self.score_head(fused_feat).squeeze(-1)  # [B]
        
        return score
```

---

### 3.2 修改 SegSolver 支持评估器训练

**文件**: `projects/scorer_solver.py`（新建）

```python
import os
import torch
import ocnn
import numpy as np
from thsolver import Solver
from datasets import get_seg_shapenet_dataset

torch.multiprocessing.set_sharing_strategy('file_system')


class ScorerSolver(Solver):
    """评估器网络训练器"""
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
    
    # ==================== Model / Dataset ====================
    def get_model(self, flags):
        from ocnn.models.scorer_net import ScorerNet
        model = ScorerNet(
            in_channels=flags.channel,
            geo_channels=flags.get('geo_channels', 256),
            rot_channels=flags.get('rot_channels', 128),
            tool_channels=flags.get('tool_channels', 64),
            interp=flags.interp,
            nempty=flags.nempty
        )
        return model
    
    def get_dataset(self, flags):
        return get_seg_shapenet_dataset(flags)
    
    def get_input_feature(self, octree):
        flags = self.FLAGS.MODEL
        octree_feature = ocnn.modules.InputFeature(flags.feature, flags.nempty)
        data = octree_feature(octree)
        return data
    
    # ==================== Batch Processing ====================
    def process_batch(self, batch, flags):
        """处理batch，移到GPU"""
        if 'octree' in batch:
            batch['octree'] = batch['octree'].cuda(non_blocking=True)
            batch['points'] = batch['points'].cuda(non_blocking=True)
        
        # 转换其他字段
        if 'labels' in batch:
            batch['labels'] = batch['labels'].cuda(non_blocking=True)
        if 'rotation_matrices' in batch:
            batch['rotation_matrices'] = batch['rotation_matrices'].cuda(non_blocking=True)
        
        return batch
    
    def _to_cuda_float_tensor(self, x):
        """转换为CUDA float tensor"""
        if isinstance(x, torch.Tensor):
            return x.to(dtype=torch.float32, device='cuda')
        
        import numpy as np
        try:
            x_np = np.array(x, dtype=np.float32)
        except (TypeError, ValueError):
            x_np = np.array([[str(v).strip() for v in row] for row in x], dtype=np.float32)
        
        return torch.from_numpy(x_np).to(device='cuda')
    
    # ==================== Training Strategy ====================
    def sample_rotation_indices(self, B, strategy='uniform'):
        """
        为每个样本采样一个旋转矩阵索引
        
        Args:
            B: batch size
            strategy: 采样策略
                - 'uniform': 均匀随机采样
                - 'hard': 困难样本挖掘（高分数区域）
                - 'mixed': 混合采样
        
        Returns:
            indices: [B] 旋转矩阵索引
        """
        if strategy == 'uniform':
            # 均匀随机采样
            indices = torch.randint(0, 338, (B,), device='cuda')
        elif strategy == 'hard':
            # 困难样本挖掘：从分数较高的前50%中采样
            # 这需要在forward中实现，这里先用uniform
            indices = torch.randint(0, 338, (B,), device='cuda')
        else:  # mixed
            # 80%均匀，20%困难
            num_uniform = int(0.8 * B)
            uniform_indices = torch.randint(0, 338, (num_uniform,), device='cuda')
            hard_indices = torch.randint(0, 169, (B - num_uniform,), device='cuda')  # 前50%
            indices = torch.cat([uniform_indices, hard_indices])
            indices = indices[torch.randperm(B)]
        
        return indices
    
    def model_forward(self, batch, rot_indices=None):
        """
        模型前向传播
        
        Args:
            batch: 数据批次
            rot_indices: [B] 指定的旋转矩阵索引（可选，用于推理）
        
        Returns:
            score_pred: [B] 预测分数
            score_gt: [B] 真实分数
        """
        octree, points = batch['octree'], batch['points']
        data = self.get_input_feature(octree)
        query_pts = torch.cat([points.points, points.batch_id], dim=1)
        
        B = batch['labels'].size(0)
        
        # 采样旋转矩阵索引
        if rot_indices is None:
            rot_indices = self.sample_rotation_indices(B, strategy='uniform')
        
        # 获取对应的旋转矩阵
        rotation_matrices = batch['rotation_matrices']  # [338, 3, 3]
        selected_rotations = rotation_matrices[rot_indices]  # [B, 3, 3]
        
        # 获取刀具参数
        tool_params = self._to_cuda_float_tensor(batch['tool_params'])  # [B, 4]
        
        # 前向传播
        score_pred = self.model.forward(
            data, octree, octree.depth, query_pts,
            selected_rotations, tool_params
        )  # [B]
        
        # 获取对应的GT分数
        labels = batch['labels']  # [B, 338]
        score_gt = labels[torch.arange(B, device='cuda'), rot_indices]  # [B]
        
        return score_pred, score_gt, rot_indices
    
    # ==================== Loss & Metrics ====================
    def loss_function(self, score_pred, score_gt):
        """
        MSE loss
        """
        loss = torch.nn.functional.mse_loss(score_pred, score_gt)
        return loss
    
    def loss_function_huber(self, score_pred, score_gt, delta=1.0):
        """
        Huber loss（对outlier更鲁棒）
        """
        loss = torch.nn.functional.huber_loss(score_pred, score_gt, delta=delta)
        return loss
    
    def mae(self, score_pred, score_gt):
        """平均绝对误差"""
        return torch.abs(score_pred - score_gt).mean().item()
    
    def rmse(self, score_pred, score_gt):
        """均方根误差"""
        return torch.sqrt(torch.mean((score_pred - score_gt) ** 2)).item()
    
    def relative_error(self, score_pred, score_gt):
        """相对误差（百分比）"""
        rel_err = torch.abs(score_pred - score_gt) / (score_gt.abs() + 1e-6)
        return (rel_err.mean() * 100).item()
    
    # ==================== Train / Test Steps ====================
    def train_step(self, batch):
        batch = self.process_batch(batch, self.FLAGS.DATA.train)
        score_pred, score_gt, _ = self.model_forward(batch)
        
        # 计算损失
        loss = self.loss_function(score_pred, score_gt)
        
        # 计算指标
        mae = self.mae(score_pred, score_gt)
        rmse_val = self.rmse(score_pred, score_gt)
        rel_err = self.relative_error(score_pred, score_gt)
        
        return {
            'train/loss': loss,
            'train/mae': torch.tensor(mae, dtype=torch.float32, device=loss.device),
            'train/rmse': torch.tensor(rmse_val, dtype=torch.float32, device=loss.device),
            'train/rel_error': torch.tensor(rel_err, dtype=torch.float32, device=loss.device),
        }
    
    def test_step(self, batch):
        batch = self.process_batch(batch, self.FLAGS.DATA.test)
        with torch.no_grad():
            score_pred, score_gt, _ = self.model_forward(batch)
            
            loss = self.loss_function(score_pred, score_gt)
            mae = self.mae(score_pred, score_gt)
            rmse_val = self.rmse(score_pred, score_gt)
            rel_err = self.relative_error(score_pred, score_gt)
        
        return {
            'test/loss': loss,
            'test/mae': torch.tensor(mae, dtype=torch.float32, device=loss.device),
            'test/rmse': torch.tensor(rmse_val, dtype=torch.float32, device=loss.device),
            'test/rel_error': torch.tensor(rel_err, dtype=torch.float32, device=loss.device),
        }
    
    def eval_step(self, batch):
        """
        评估：对每个样本测试所有338个姿态
        """
        batch = self.process_batch(batch, self.FLAGS.DATA.test)
        B = batch['labels'].size(0)
        
        with torch.no_grad():
            all_scores = []
            
            # 遍历所有338个姿态
            for rot_idx in range(338):
                rot_indices = torch.full((B,), rot_idx, device='cuda')
                score_pred, _, _ = self.model_forward(batch, rot_indices)
                all_scores.append(score_pred.cpu().numpy())
            
            all_scores = np.stack(all_scores, axis=1)  # [B, 338]
            labels_gt = batch['labels'].cpu().numpy()  # [B, 338]
            
            # 保存结果
            filenames = batch['filename']
            for i, fname in enumerate(filenames):
                self.eval_rst[fname] = {
                    'scores_pred': all_scores[i],  # [338]
                    'scores_gt': labels_gt[i],     # [338]
                }
                
                # 最后一个epoch保存
                if self.FLAGS.SOLVER.eval_epoch - 1 == batch['epoch']:
                    full_filename = os.path.join(
                        self.logdir, fname[:-4] + '.scorer_eval.npz'
                    )
                    curr_folder = os.path.dirname(full_filename)
                    if not os.path.exists(curr_folder):
                        os.makedirs(curr_folder)
                    np.savez(
                        full_filename,
                        scores_pred=self.eval_rst[fname]['scores_pred'],
                        scores_gt=self.eval_rst[fname]['scores_gt'],
                    )
    
    def result_callback(self, avg_tracker, epoch):
        """打印结果"""
        from tqdm import tqdm
        avg = avg_tracker.average()
        
        def _to_float(x, default=0.0):
            if x is None:
                return default
            if isinstance(x, torch.Tensor):
                return x.detach().item()
            try:
                return float(x)
            except Exception:
                return default
        
        loss = _to_float(avg.get('test/loss'))
        mae = _to_float(avg.get('test/mae'))
        rmse = _to_float(avg.get('test/rmse'))
        rel_err = _to_float(avg.get('test/rel_error'))
        
        tqdm.write(f'=> Epoch: {epoch} | '
                   f'loss: {loss:.6f} | '
                   f'MAE: {mae:.6f} | '
                   f'RMSE: {rmse:.6f} | '
                   f'Rel.Err: {rel_err:.2f}%')


if __name__ == "__main__":
    ScorerSolver.main()
```

---

### 3.3 配置文件

**文件**: `projects/configs/scorer_deepmill.yaml`

```yaml
SOLVER:
  run: train
  gpu: (0,)
  type: adam              # 使用Adam优化器
  lr: 0.001               # 学习率
  weight_decay: 0.0001    # 权重衰减
  best_val: min:test/mae  # 最优模型选择指标
  
  logdir: logs/scorer_deepmill/baseline
  max_epoch: 300
  test_every_epoch: 10
  
  milestones: (120, 200, 260)
  ckpt_num: 20

DATA:
  train:
    name: shapenet
    
    # octree building
    depth: 5
    full_depth: 2
    
    # transformation
    orient_normal: xyz
    
    # data augmentation
    distort: True
    angle: (0, 5, 0)
    interval: (1, 1, 1)
    scale: 0.25
    jitter: 0.25
    uniform: True
    
    # loading
    location: data_2.0/points
    filelist: data_2.0/filelist/models_train_val.txt
    batch_size: 8
    shuffle: True
    num_workers: 0
  
  test:
    name: shapenet
    
    # octree building
    depth: 5
    full_depth: 2
    
    # transformation
    orient_normal: xyz
    
    # no augmentation for test
    distort: False
    angle: (0, 0, 0)
    interval: (1, 1, 1)
    scale: 0.0
    jitter: 0.0
    uniform: True
    
    # loading
    location: data_2.0/points
    filelist: data_2.0/filelist/models_test.txt
    batch_size: 1
    shuffle: False
    num_workers: 0

MODEL:
  feature: ND
  interp: 'linear'
  channel: 4
  nempty: False
  
  # Scorer-specific
  geo_channels: 256     # 几何特征维度
  rot_channels: 128     # 旋转特征维度
  tool_channels: 64     # 刀具特征维度

LOSS:
  type: mse              # 或 'huber'
  huber_delta: 1.0       # Huber loss的delta参数
```

---

### 3.4 启动脚本

**文件**: `projects/run_scorer_deepmill.py`

```python
import os
import argparse
import subprocess

parser = argparse.ArgumentParser()
parser.add_argument('--alias', type=str, default='scorer_baseline', help='log alias')
parser.add_argument('--gpu', type=str, default='0', help='CUDA visible devices')
parser.add_argument('--depth', type=int, default=5, help='octree depth')
parser.add_argument('--ckpt', type=str, default='', help='checkpoint path')
parser.add_argument('--ratios', type=float, default=[1.0], nargs='*', help='train ratios')

args = parser.parse_args()

alias = args.alias
gpu = args.gpu
ratios = args.ratios

module = 'scorer_solver.py'
config_path = 'configs/scorer_deepmill.yaml'
script_base = ['python', module, '--config', config_path]

data_root = 'data_2.0'
log_root = 'logs/scorer_deepmill'

categories = ['models']
names = ['models']
train_num = [4451]
test_num = [1112]
max_epoches = [300]

def build_cmd_list(
    logdir, max_epoch, milestone1, milestone2,
    take, cat, depth, test_every_epoch
):
    cmd = script_base + [
        'SOLVER.logdir', logdir,
        'SOLVER.max_epoch', str(max_epoch),
        'SOLVER.milestones', f'({min(milestone1, milestone2)},{max(milestone1, milestone2)})',
        'SOLVER.test_every_epoch', str(test_every_epoch),
        'SOLVER.ckpt', (args.ckpt if args.ckpt != '' else "''"),
        'DATA.train.depth', str(depth),
        'DATA.train.filelist', f'{data_root}/filelist/{cat}_train_val.txt',
        'DATA.train.take', str(take),
        'DATA.test.depth', str(depth),
        'DATA.test.filelist', f'{data_root}/filelist/{cat}_test.txt',
    ]
    
    return cmd


def main():
    test_every_epoch = 10
    for i in range(len(ratios)):
        for k in range(len(categories)):
            ratio, cat = ratios[i], categories[k]
            max_epoch = int(max_epoches[k] * ratio)
            milestone1 = int(0.40 * max_epoch)
            milestone2 = int(0.70 * max_epoch)
            take = int(train_num[k] * ratio)
            logdir = os.path.join(log_root, f'{alias}/{cat}_{names[k]}/ratio_{ratio:.2f}')
            
            cmd_list = build_cmd_list(
                logdir=logdir,
                max_epoch=max_epoch,
                milestone1=milestone1,
                milestone2=milestone2,
                take=take,
                cat=cat,
                depth=args.depth,
                test_every_epoch=test_every_epoch,
            )
            
            print('\n>>> Launch command:\n', ' '.join(cmd_list), '\n')
            subprocess.run(cmd_list, check=False)


if __name__ == '__main__':
    main()
```

---

## 四、训练策略优化

### 4.1 采样策略

**问题**: 338个姿态，如何有效训练？

**方案**:

1. **均匀采样（Uniform Sampling）**
   - 每个batch随机采样姿态
   - 简单，适合初期训练

2. **困难样本挖掘（Hard Example Mining）**
   - 优先采样预测误差大的姿态
   - 加速收敛

3. **分层采样（Stratified Sampling）**
   - 根据分数分段采样
   - 平衡高分和低分样本

4. **全姿态训练（All-Pose Training）**
   - 每个样本展开为338个训练样本
   - 数据量大，训练慢但效果好

```python
# 在 scorer_solver.py 中实现

def create_all_pose_dataset(self, batch):
    """将batch展开为所有姿态的训练样本"""
    B = batch['labels'].size(0)
    
    # 复制几何数据338次
    expanded_batch = {}
    for key in ['octree', 'points', 'tool_params']:
        # 这些需要特殊处理
        pass
    
    # 生成所有姿态索引
    rot_indices = torch.arange(338).repeat(B)  # [B*338]
    
    return expanded_batch, rot_indices
```

---

### 4.2 损失函数选择

```python
# MSE Loss（默认）
loss = (score_pred - score_gt) ** 2

# Huber Loss（对outlier更鲁棒）
loss = torch.nn.functional.huber_loss(score_pred, score_gt, delta=1.0)

# 相对误差Loss
loss = torch.abs(score_pred - score_gt) / (score_gt.abs() + 1e-6)

# 排序Loss（Ranking Loss）
# 如果同时采样多个姿态，可以加入排序约束
# score_pred[i] < score_pred[j] if score_gt[i] < score_gt[j]
```

---

### 4.3 数据增强

```python
# 1. 几何增强（已有）
- 旋转、缩放、抖动

# 2. 姿态增强（新增）
- 在采样的旋转矩阵周围添加小扰动
- 模拟姿态的微小变化

def perturb_rotation(R, angle_std=5.0):
    """对旋转矩阵添加小扰动"""
    # 转为轴角表示
    # 添加高斯噪声
    # 转回旋转矩阵
    pass
```

---

## 五、使用方法

### 5.1 训练评估器

```bash
cd /home/xinguanze/project/ex_6_scorer/DM-scorer/projects

# 完整数据集训练
python run_scorer_deepmill.py \
    --alias scorer_baseline \
    --gpu 0 \
    --ratios 1.0

# 小数据集快速测试
python run_scorer_deepmill.py \
    --alias scorer_debug \
    --gpu 0 \
    --ratios 0.1
```

### 5.2 推理评估

```python
# 加载模型
from scorer_solver import ScorerSolver
solver = ScorerSolver.load_checkpoint('path/to/checkpoint.pth')

# 对单个模型评估所有姿态
scores = solver.evaluate_all_poses(point_cloud, tool_params)  # [338]

# 找到最优姿态
best_idx = scores.argmin()
best_rotation = rotation_matrices[best_idx]
```

---

## 六、与原始姿态预测的对比

| 维度 | 姿态预测网络（原始） | 评估器网络（新任务） |
|------|---------------------|---------------------|
| **输入** | 点云 + 刀具参数 | 点云 + 姿态 + 刀具参数 |
| **输出** | 2个角度 [pitch, roll] | 1个分数 |
| **训练方式** | 监督学习（软分配） | 监督学习（回归） |
| **GT** | 338维打分表 | 338维打分表（直接索引） |
| **推理** | 一次forward得到姿态 | 需遍历338次得到所有分数 |
| **用途** | 直接预测最优姿态 | 评估给定姿态的质量 |

---

## 七、总结

### 核心修改点

1. ✅ **新建ScorerNet模型** - 三分支融合架构
2. ✅ **新建ScorerSolver训练器** - 处理姿态采样和评分
3. ✅ **配置文件** - 专门的评估器配置
4. ✅ **启动脚本** - 一键训练

### 数据流

```
batch = {
    'octree': Octree对象,
    'points': Points对象,
    'labels': [B, 338] 打分表,
    'rotation_matrices': [338, 3, 3] 预定义姿态,
    'tool_params': [B, 4] 刀具参数
}
    ↓
随机采样 rot_indices [B] (0~337)
    ↓
selected_rotations = rotation_matrices[rot_indices]  # [B, 3, 3]
score_gt = labels[range(B), rot_indices]  # [B]
    ↓
score_pred = ScorerNet(octree, selected_rotations, tool_params)  # [B]
    ↓
loss = MSE(score_pred, score_gt)
```

### 下一步

1. 实现 `ScorerNet` 模型
2. 实现 `ScorerSolver` 训练器
3. 测试数据流是否正确
4. 开始训练并监控指标

---

**文档版本**: v1.0  
**创建日期**: 2025-11-06  
**作者**: AI Assistant

